{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77344eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'continent': 'Africa',\n",
      " 'country': 'Kenya',\n",
      " 'creation_date': '2025-08-12 18:18:18',\n",
      " 'dahiti_id': '40216',\n",
      " 'data': [{'datetime': '2018-12-28 07:29:44', 'wse': 1052.33, 'wse_u': 0.003},\n",
      "          {'datetime': '2019-01-24 07:29:45', 'wse': 1051.334, 'wse_u': 0.001},\n",
      "          {'datetime': '2019-02-20 07:29:46', 'wse': 1049.362, 'wse_u': 0.009},\n",
      "          {'datetime': '2019-03-19 07:29:50', 'wse': 1045.828, 'wse_u': 0.059},\n",
      "          {'datetime': '2019-04-15 07:29:51', 'wse': 1043.745, 'wse_u': 0.066},\n",
      "          {'datetime': '2019-05-12 07:29:50', 'wse': 1044.557, 'wse_u': 0.002},\n",
      "          {'datetime': '2019-06-08 07:29:44', 'wse': 1046.0, 'wse_u': 0.01},\n",
      "          {'datetime': '2019-07-05 07:29:45', 'wse': 1045.812, 'wse_u': 0.002},\n",
      "          {'datetime': '2019-08-01 07:29:47', 'wse': 1043.824, 'wse_u': 0.008},\n",
      "          {'datetime': '2019-08-28 07:29:46', 'wse': 1041.137, 'wse_u': 0.003},\n",
      "          {'datetime': '2019-10-21 07:29:42', 'wse': 1043.68, 'wse_u': 0.046},\n",
      "          {'datetime': '2019-11-17 07:29:47', 'wse': 1049.794, 'wse_u': 0.012},\n",
      "          {'datetime': '2019-12-14 07:29:47', 'wse': 1057.919, 'wse_u': 0.002},\n",
      "          {'datetime': '2020-01-10 07:29:46', 'wse': 1057.59, 'wse_u': 0.003},\n",
      "          {'datetime': '2020-02-06 07:29:43', 'wse': 1057.566, 'wse_u': 0.01},\n",
      "          {'datetime': '2020-03-31 07:29:48', 'wse': 1057.51, 'wse_u': 0.0},\n",
      "          {'datetime': '2020-04-27 07:29:51', 'wse': 1058.244, 'wse_u': 0.001},\n",
      "          {'datetime': '2020-05-24 07:29:53', 'wse': 1057.88, 'wse_u': 0.006},\n",
      "          {'datetime': '2020-07-17 07:29:58', 'wse': 1057.047, 'wse_u': 0.004},\n",
      "          {'datetime': '2020-08-13 07:29:58', 'wse': 1056.264, 'wse_u': 0.015},\n",
      "          {'datetime': '2020-09-09 07:29:57', 'wse': 1055.619, 'wse_u': 0.001},\n",
      "          {'datetime': '2020-10-06 07:29:53', 'wse': 1054.701, 'wse_u': 0.0},\n",
      "          {'datetime': '2020-11-02 07:29:58', 'wse': 1053.916, 'wse_u': 0.002},\n",
      "          {'datetime': '2020-11-29 07:29:59', 'wse': 1054.582, 'wse_u': 0.002},\n",
      "          {'datetime': '2020-12-26 07:29:58', 'wse': 1053.3, 'wse_u': 0.003},\n",
      "          {'datetime': '2021-01-22 07:29:57', 'wse': 1052.958, 'wse_u': 0.019},\n",
      "          {'datetime': '2021-02-18 07:29:56', 'wse': 1052.356, 'wse_u': 0.003},\n",
      "          {'datetime': '2021-03-17 07:29:58', 'wse': 1051.727, 'wse_u': 0.002},\n",
      "          {'datetime': '2021-04-13 07:29:56', 'wse': 1051.101, 'wse_u': 0.002},\n",
      "          {'datetime': '2021-05-10 07:30:00', 'wse': 1052.653, 'wse_u': 0.005},\n",
      "          {'datetime': '2021-06-06 07:30:04', 'wse': 1055.245, 'wse_u': 0.0},\n",
      "          {'datetime': '2021-07-03 07:30:07', 'wse': 1054.673, 'wse_u': 0.0},\n",
      "          {'datetime': '2021-07-30 07:30:08', 'wse': 1054.164, 'wse_u': 0.065},\n",
      "          {'datetime': '2021-08-26 07:30:09', 'wse': 1052.975, 'wse_u': 0.019},\n",
      "          {'datetime': '2021-09-22 07:30:07', 'wse': 1051.754, 'wse_u': 0.013},\n",
      "          {'datetime': '2021-10-19 07:30:02', 'wse': 1050.526, 'wse_u': 0.012},\n",
      "          {'datetime': '2021-11-15 07:30:05', 'wse': 1049.78, 'wse_u': 0.004},\n",
      "          {'datetime': '2021-12-12 07:30:05', 'wse': 1050.665, 'wse_u': 0.002},\n",
      "          {'datetime': '2022-01-08 07:30:04', 'wse': 1050.642, 'wse_u': 0.01},\n",
      "          {'datetime': '2022-02-04 07:30:01', 'wse': 1049.383, 'wse_u': 0.003},\n",
      "          {'datetime': '2022-03-03 07:30:04', 'wse': 1047.649, 'wse_u': 0.024},\n",
      "          {'datetime': '2022-03-30 07:30:03', 'wse': 1045.86, 'wse_u': 0.021},\n",
      "          {'datetime': '2022-04-26 07:30:06', 'wse': 1045.775, 'wse_u': 0.013},\n",
      "          {'datetime': '2022-05-23 07:30:11', 'wse': 1047.887, 'wse_u': 0.002},\n",
      "          {'datetime': '2022-06-19 07:30:16', 'wse': 1047.257, 'wse_u': 0.036},\n",
      "          {'datetime': '2022-07-16 07:30:18', 'wse': 1045.643, 'wse_u': 0.002},\n",
      "          {'datetime': '2022-08-12 07:30:17', 'wse': 1043.786, 'wse_u': 0.044},\n",
      "          {'datetime': '2022-09-08 07:30:17', 'wse': 1042.233, 'wse_u': 0.051},\n",
      "          {'datetime': '2022-10-05 07:30:13', 'wse': 1041.205, 'wse_u': 0.025},\n",
      "          {'datetime': '2022-11-01 07:30:18', 'wse': 1040.902, 'wse_u': 0.029},\n",
      "          {'datetime': '2023-01-21 07:30:13', 'wse': 1039.785, 'wse_u': 0.047},\n",
      "          {'datetime': '2023-02-17 07:30:17', 'wse': 1039.623, 'wse_u': 0.024},\n",
      "          {'datetime': '2023-03-16 07:30:16', 'wse': 1039.604, 'wse_u': 0.006},\n",
      "          {'datetime': '2023-04-12 07:30:16', 'wse': 1040.714, 'wse_u': 0.051},\n",
      "          {'datetime': '2023-05-09 07:30:19', 'wse': 1043.335, 'wse_u': 0.01},\n",
      "          {'datetime': '2023-06-05 07:30:22', 'wse': 1045.504, 'wse_u': 0.022},\n",
      "          {'datetime': '2023-07-02 07:30:25', 'wse': 1044.805, 'wse_u': 0.004},\n",
      "          {'datetime': '2023-07-29 07:30:26', 'wse': 1043.464, 'wse_u': 0.003},\n",
      "          {'datetime': '2023-08-25 07:30:27', 'wse': 1041.434, 'wse_u': 0.004},\n",
      "          {'datetime': '2023-09-21 07:30:22', 'wse': 1040.182, 'wse_u': 0.012},\n",
      "          {'datetime': '2023-10-18 07:30:27', 'wse': 1040.294, 'wse_u': 0.01},\n",
      "          {'datetime': '2023-11-14 07:30:28', 'wse': 1043.358, 'wse_u': 0.034},\n",
      "          {'datetime': '2023-12-11 07:30:27', 'wse': 1052.815, 'wse_u': 0.008},\n",
      "          {'datetime': '2024-01-07 07:30:23', 'wse': 1054.812, 'wse_u': 0.006},\n",
      "          {'datetime': '2024-02-03 07:30:25', 'wse': 1056.471, 'wse_u': 0.0},\n",
      "          {'datetime': '2024-03-01 07:30:28', 'wse': 1055.682, 'wse_u': 0.005},\n",
      "          {'datetime': '2024-03-28 07:30:24', 'wse': 1054.738, 'wse_u': 0.017},\n",
      "          {'datetime': '2024-04-24 07:30:30', 'wse': 1058.486, 'wse_u': 0.019},\n",
      "          {'datetime': '2024-05-21 07:30:34', 'wse': 1058.453, 'wse_u': 0.003},\n",
      "          {'datetime': '2024-06-17 07:30:38', 'wse': 1058.031, 'wse_u': 0.008},\n",
      "          {'datetime': '2024-07-14 07:30:40', 'wse': 1057.625, 'wse_u': 0.004},\n",
      "          {'datetime': '2024-08-10 07:30:40', 'wse': 1057.515, 'wse_u': 0.024},\n",
      "          {'datetime': '2024-10-03 07:30:34', 'wse': 1056.237, 'wse_u': 0.015},\n",
      "          {'datetime': '2024-11-26 07:30:41', 'wse': 1055.648, 'wse_u': 0.008},\n",
      "          {'datetime': '2024-12-23 07:30:38', 'wse': 1056.182, 'wse_u': 0.001}],\n",
      " 'dataset': 'water-level-altimetry',\n",
      " 'geoid': -16.7334,\n",
      " 'institution': 'DGFI-TUM',\n",
      " 'latitude': -0.8736,\n",
      " 'location': None,\n",
      " 'longitude': 37.4316,\n",
      " 'software': 8.0,\n",
      " 'source': 'DAHITI',\n",
      " 'target_name': 'Masinga, Reservoir',\n",
      " 'url': 'https://dahiti.dgfi.tum.de/40216/'}\n",
      "Saved water level data to masinga_water_levels.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://dahiti.dgfi.tum.de/api/v2/download-water-level/\"\n",
    "\n",
    "args = {\n",
    "    'api_key': '0068D5A859F71E204F7C0A7D5BEA1D2ADB495E22EECB95C51F871337A4B79453',\n",
    "    'dahiti_id': 40216,  # Masinga Dam ID\n",
    "    'format': 'json'     # json format response\n",
    "}\n",
    "\n",
    "response = requests.get(url, params=args)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    if args['format'] == \"ascii\":\n",
    "        data_ascii = response.text\n",
    "        print(data_ascii)\n",
    "    elif args['format'] == \"json\":\n",
    "        data_json = json.loads(response.text)\n",
    "        pprint.pprint(data_json)\n",
    "        \n",
    "        # ---- Save JSON data to CSV ----\n",
    "        # Extract the relevant part: usually the 'data' key contains rows\n",
    "        records = data_json.get('data', [])\n",
    "        \n",
    "        # Convert list of dicts to pandas DataFrame\n",
    "        df = pd.DataFrame(records)\n",
    "        \n",
    "        # Save DataFrame to CSV file\n",
    "        df.to_csv('masinga_water_levels.csv', index=False)\n",
    "        print(\"Saved water level data to masinga_water_levels.csv\")\n",
    "        \n",
    "    elif args['format'] == \"netcdf\":\n",
    "        path_netcdf = \"/tmp/\" + str(args['dahiti_id']) + \"_water_level_altimetry.nc\"\n",
    "        print('writing ... ' + path_netcdf)\n",
    "        with open(path_netcdf, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print('done!')\n",
    "    elif args['format'] == \"csv\":\n",
    "        data_csv = response.text\n",
    "        print(data_csv)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b610880c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " datetime    0\n",
      "wse         0\n",
      "wse_u       0\n",
      "dtype: int64\n",
      "Missing values after conversion:\n",
      " datetime    0\n",
      "wse         0\n",
      "wse_u       0\n",
      "dtype: int64\n",
      "             datetime       wse  wse_u\n",
      "0 2018-12-28 07:29:44  1052.330  0.003\n",
      "1 2019-01-24 07:29:45  1051.334  0.001\n",
      "2 2019-02-20 07:29:46  1049.362  0.009\n",
      "3 2019-03-19 07:29:50  1045.828  0.059\n",
      "4 2019-04-15 07:29:51  1043.745  0.066\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the data (assuming CSV file)\n",
    "df = pd.read_csv('masinga_water_levels.csv')\n",
    "\n",
    "# Step 2: Convert datetime column to datetime type\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Step 3: Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Step 4: Remove duplicates if any\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Step 5: Sort by datetime\n",
    "df = df.sort_values(by='datetime').reset_index(drop=True)\n",
    "\n",
    "# Step 6: Convert wse and wse_u to float (if not already)\n",
    "df['wse'] = pd.to_numeric(df['wse'], errors='coerce')\n",
    "df['wse_u'] = pd.to_numeric(df['wse_u'], errors='coerce')\n",
    "\n",
    "# Step 7: Final check for any NaNs after conversions\n",
    "print(\"Missing values after conversion:\\n\", df.isnull().sum())\n",
    "\n",
    "# Optional: filter data between 2018-01-01 and 2020-12-31 for your project scope\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2020-12-31'\n",
    "df_filtered = df[(df['datetime'] >= start_date) & (df['datetime'] <= end_date)]\n",
    "\n",
    "print(df_filtered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e2b94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [37.53, -0.87, 1227.42]}, 'properties': {'parameter': {'PRECTOTCORR': {'201801': 0.16, '201802': 0.41, '201803': 7.23, '201804': 11.2, '201805': 3.72, '201806': 1.39, '201807': 0.71, '201808': 0.73, '201809': 0.47, '201810': 1.46, '201811': 2.34, '201812': 4.44, '201813': 2.86, '201901': 0.84, '201902': 0.21, '201903': 0.47, '201904': 1.72, '201905': 1.69, '201906': 2.12, '201907': 0.72, '201908': 0.64, '201909': 0.67, '201910': 5.45, '201911': 5.1, '201912': 5.08, '201913': 2.07, '202001': 3.02, '202002': 1.57, '202003': 2.93, '202004': 8.79, '202005': 1.58, '202006': 2.18, '202007': 0.6, '202008': 0.8, '202009': 1.94, '202010': 3.05, '202011': 5.21, '202012': 1.72, '202013': 2.77}}}, 'header': {'title': 'NASA/POWER Source Native Resolution Monthly and Annual', 'api': {'version': 'v2.7.3', 'name': 'POWER Monthly and Annual API'}, 'sources': ['MERRA2'], 'fill_value': -999.0, 'time_standard': 'LST', 'start': '20180101', 'end': '20201231'}, 'messages': [], 'parameters': {'PRECTOTCORR': {'units': 'mm/day', 'longname': 'Precipitation Corrected'}}, 'times': {'data': 4.397, 'process': 0.06}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# NASA POWER API parameters\n",
    "latitude = -0.87   # Example: Masinga Dam latitude\n",
    "longitude = 37.53  # Example: Masinga Dam longitude\n",
    "start = 2018\n",
    "end = 2020\n",
    "\n",
    "url = f\"https://power.larc.nasa.gov/api/temporal/monthly/point\"\n",
    "params = {\n",
    "    \"parameters\": \"PRECTOT\",  # Total monthly precipitation\n",
    "    \"community\": \"AG\",\n",
    "    \"longitude\": longitude,\n",
    "    \"latitude\": latitude,\n",
    "    \"start\": start,\n",
    "    \"end\": end,\n",
    "    \"format\": \"JSON\"\n",
    "}\n",
    "\n",
    "# Make request\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Print raw JSON to debug\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "511a425f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'wse', 'wse_u'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca0f7c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 3)\n",
      "           date  temperature_C  precipitation_mm\n",
      "1091 2020-12-27          19.63              0.02\n",
      "1092 2020-12-28          19.54              0.20\n",
      "1093 2020-12-29          20.68              0.28\n",
      "1094 2020-12-30          20.66              5.18\n",
      "1095 2020-12-31          18.60             21.98\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "lat, lon = -0.75, 37.5\n",
    "\n",
    "def fetch_weather_data(start_date, end_date):\n",
    "    url = (\n",
    "        f\"https://power.larc.nasa.gov/api/temporal/daily/point?\"\n",
    "        f\"parameters=T2M,PRECTOTCORR&community=AG&longitude={lon}&latitude={lat}\"\n",
    "        f\"&start={start_date}&end={end_date}&format=JSON\"\n",
    "    )\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    temp_data = data['properties']['parameter']['T2M']\n",
    "    precip_data = data['properties']['parameter']['PRECTOTCORR']\n",
    "    \n",
    "    dates = []\n",
    "    temps = []\n",
    "    precip = []\n",
    "    \n",
    "    for date_str in temp_data.keys():\n",
    "        dates.append(pd.to_datetime(date_str, format='%Y%m%d'))\n",
    "        temps.append(temp_data[date_str])\n",
    "        precip.append(precip_data.get(date_str, None))\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'temperature_C': temps,\n",
    "        'precipitation_mm': precip\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Fetch 2018 data\n",
    "df_2018 = fetch_weather_data('20180101', '20181231')\n",
    "# Fetch 2019 data\n",
    "df_2019 = fetch_weather_data('20190101', '20191231')\n",
    "# Fetch 2020 data\n",
    "df_2020 = fetch_weather_data('20200101', '20201231')\n",
    "\n",
    "# Combine all years\n",
    "weather_df = pd.concat([df_2018, df_2019, df_2020], ignore_index=True)\n",
    "\n",
    "print(weather_df.shape)\n",
    "print(weather_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "099bdbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'temperature_C', 'precipitation_mm'], dtype='object')\n",
      "date                0\n",
      "temperature_C       0\n",
      "precipitation_mm    0\n",
      "dtype: int64\n",
      "                      date  temperature_C  precipitation_mm\n",
      "count                 1096    1096.000000       1096.000000\n",
      "mean   2019-07-02 12:00:00      20.198677          3.706770\n",
      "min    2018-01-01 00:00:00      15.770000          0.000000\n",
      "25%    2018-10-01 18:00:00      19.267500          0.480000\n",
      "50%    2019-07-02 12:00:00      20.160000          1.450000\n",
      "75%    2020-04-01 06:00:00      21.072500          3.850000\n",
      "max    2020-12-31 00:00:00      24.970000         60.810000\n",
      "std                    NaN       1.562804          6.579551\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load data\n",
    "weather_df = pd.read_csv('masinga_weather_2018_2020.csv')\n",
    "\n",
    "# Step 2: Check columns\n",
    "print(weather_df.columns)\n",
    "\n",
    "# Step 3: Convert date to datetime\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "\n",
    "# Step 4: Check for missing values\n",
    "print(weather_df.isnull().sum())\n",
    "\n",
    "# Step 5: Basic stats\n",
    "print(weather_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aadc57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.to_csv('masinga_weather_2018_2020.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3b4b9d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sub-County'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JOY\\Desktop\\py_data\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Sub-County'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mkenya_population_data.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Step 3: Filter population data for Masinga Sub-County\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m masinga_population = df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSub-County\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[33m'\u001b[39m\u001b[33mMasinga\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Print population info for 2019\u001b[39;00m\n\u001b[32m     17\u001b[39m pop_2019 = masinga_population[\u001b[33m'\u001b[39m\u001b[33mPopulation\u001b[39m\u001b[33m'\u001b[39m].values[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JOY\\Desktop\\py_data\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JOY\\Desktop\\py_data\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Sub-County'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Step 1: Download the CSV file\n",
    "csv_url = \"https://open.africa/dataset/9b94fe50-9d75-4b92-be00-6354c6e6cc88/resource/111a3d9d-c676-4d5a-9600-d5acb1250b87/download/population-houseshold-data.csv\"\n",
    "response = requests.get(csv_url)\n",
    "with open('kenya_population_data.csv', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "# Step 2: Load CSV into a DataFrame\n",
    "df = pd.read_csv('kenya_population_data.csv')\n",
    "\n",
    "# Step 3: Filter population data for Masinga Sub-County\n",
    "masinga_population = df[df['Sub-County'] == 'Masinga']\n",
    "\n",
    "# Print population info for 2019\n",
    "pop_2019 = masinga_population['Population'].values[0]\n",
    "print(f\"Masinga Sub-County population in 2019 (census): {pop_2019}\")\n",
    "\n",
    "# Step 4: Estimate population for 2018 and 2020 (using 2.3% growth rate)\n",
    "growth_rate = 0.023\n",
    "pop_2018 = pop_2019 / (1 + growth_rate)\n",
    "pop_2020 = pop_2019 * (1 + growth_rate)\n",
    "\n",
    "print(f\"Estimated population in 2018: {int(pop_2018)}\")\n",
    "print(f\"Estimated population in 2020: {int(pop_2020)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7924412f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name  Population  No.of Households  Avg Household size\n",
      "0       Kenya    47213282          12143913                  39\n",
      "1     Mombasa     1190987            378422                  31\n",
      "2       Kwale      858748            173176                  50\n",
      "3      Kilifi     1440958            298472                  48\n",
      "4  Tana River      314710             68242                  46\n",
      "Index(['name', 'Population', 'No.of Households', 'Avg Household size'], dtype='object')\n",
      "(1, 4)\n",
      "       name  Population  No.of Households  Avg Household size\n",
      "0  Machakos     1414022            402466                  35\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV, skipping metadata rows\n",
    "population_df = pd.read_csv('kenya_population_data.csv', skiprows=6)\n",
    "\n",
    "# Check first few rows and columns (optional)\n",
    "print(population_df.head())\n",
    "print(population_df.columns)\n",
    "\n",
    "# Make sure Population, Households, Avg Household size are numeric\n",
    "population_df['Population'] = pd.to_numeric(population_df['Population'], errors='coerce')\n",
    "population_df['No.of Households'] = pd.to_numeric(population_df['No.of Households'], errors='coerce')\n",
    "population_df['Avg Household size'] = pd.to_numeric(population_df['Avg Household size'], errors='coerce')\n",
    "\n",
    "# Remove any rows with NaN in 'name'\n",
    "population_df = population_df.dropna(subset=['name'])\n",
    "\n",
    "# Filter for Machakos county only\n",
    "population_machakos = population_df[population_df['name'].str.strip().str.lower() == 'machakos'].reset_index(drop=True)\n",
    "\n",
    "# Check shape and preview\n",
    "print(population_machakos.shape)\n",
    "print(population_machakos.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc340cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'wse', 'wse_u'], dtype='object')\n",
      "      date_x  temperature_C  precipitation_mm            datetime       wse  \\\n",
      "0 2018-12-28          20.34              0.69 2018-12-28 07:29:44  1052.330   \n",
      "1 2019-01-24          21.40              0.00 2019-01-24 07:29:45  1051.334   \n",
      "2 2019-02-20          22.73              0.27 2019-02-20 07:29:46  1049.362   \n",
      "3 2019-03-19          23.91              0.04 2019-03-19 07:29:50  1045.828   \n",
      "4 2019-04-15          23.77              0.06 2019-04-15 07:29:51  1043.745   \n",
      "\n",
      "   wse_u  population_machakos  \n",
      "0  0.003              1414022  \n",
      "1  0.001              1414022  \n",
      "2  0.009              1414022  \n",
      "3  0.059              1414022  \n",
      "4  0.066              1414022  \n",
      "(25, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load weather data\n",
    "weather_df = pd.read_csv('masinga_weather_2018_2020.csv')\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "\n",
    "# Load population data with skiprows=6 because of metadata in the first 6 rows\n",
    "population_df = pd.read_csv('kenya_population_data.csv', skiprows=6)\n",
    "population_df['Population'] = pd.to_numeric(population_df['Population'], errors='coerce')\n",
    "population_df['name'] = population_df['name'].str.strip()\n",
    "\n",
    "# Filter for Machakos county only\n",
    "population_machakos = population_df[population_df['name'] == 'Machakos'].reset_index(drop=True)\n",
    "\n",
    "# Load water level data\n",
    "water_df = pd.read_csv('masinga_water_levels.csv')\n",
    "\n",
    "# Fix the column name if necessary (your earlier error was about '.datetime' column missing)\n",
    "# Check columns to find the correct datetime column name:\n",
    "print(water_df.columns)\n",
    "\n",
    "# Assuming column name is 'datetime' or similar, if not adjust accordingly\n",
    "if '.datetime' in water_df.columns:\n",
    "    datetime_col = '.datetime'\n",
    "elif 'datetime' in water_df.columns:\n",
    "    datetime_col = 'datetime'\n",
    "else:\n",
    "    # Use first column as datetime, if appropriate\n",
    "    datetime_col = water_df.columns[0]\n",
    "\n",
    "# Convert datetime column to datetime type\n",
    "water_df[datetime_col] = pd.to_datetime(water_df[datetime_col])\n",
    "\n",
    "# Create a date-only column for merging\n",
    "water_df['date'] = water_df[datetime_col].dt.date\n",
    "weather_df['date_only'] = weather_df['date'].dt.date\n",
    "\n",
    "# Merge weather and water levels on date\n",
    "merged_df = pd.merge(weather_df, water_df, left_on='date_only', right_on='date', how='inner')\n",
    "\n",
    "# Drop duplicate date columns to clean up\n",
    "merged_df = merged_df.drop(columns=['date_only', 'date_y'])\n",
    "\n",
    "# Add Machakos population as a constant column for analysis\n",
    "merged_df['population_machakos'] = population_machakos.loc[0, 'Population']\n",
    "\n",
    "# Inspect the final merged dataframe\n",
    "print(merged_df.head())\n",
    "print(merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a79ccf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename date_x to just date for clarity\n",
    "merged_df = merged_df.rename(columns={'date_x': 'date'})\n",
    "\n",
    "# If you want to keep datetime from water data but align it with date only, you can keep both or drop one\n",
    "# For example, drop 'datetime' if you prefer just the date:\n",
    "merged_df = merged_df.drop(columns=['datetime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c977024b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_C</th>\n",
       "      <th>precipitation_mm</th>\n",
       "      <th>wse</th>\n",
       "      <th>wse_u</th>\n",
       "      <th>population_machakos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>20.34</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1052.330</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1414022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>21.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1051.334</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1414022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-20</td>\n",
       "      <td>22.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1049.362</td>\n",
       "      <td>0.009</td>\n",
       "      <td>1414022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>23.91</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1045.828</td>\n",
       "      <td>0.059</td>\n",
       "      <td>1414022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>23.77</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1043.745</td>\n",
       "      <td>0.066</td>\n",
       "      <td>1414022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  temperature_C  precipitation_mm       wse  wse_u  \\\n",
       "0 2018-12-28          20.34              0.69  1052.330  0.003   \n",
       "1 2019-01-24          21.40              0.00  1051.334  0.001   \n",
       "2 2019-02-20          22.73              0.27  1049.362  0.009   \n",
       "3 2019-03-19          23.91              0.04  1045.828  0.059   \n",
       "4 2019-04-15          23.77              0.06  1043.745  0.066   \n",
       "\n",
       "   population_machakos  \n",
       "0              1414022  \n",
       "1              1414022  \n",
       "2              1414022  \n",
       "3              1414022  \n",
       "4              1414022  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
